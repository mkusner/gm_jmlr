%!TEX root=gm_jmlr.tex 

Gradient Boosted Regression Tree (GBRT) algorithms have been widely used in many real-world applications such as web-search ranking, image detection and budgeted learning. This is largely due to its robustness to noisy data, non-linear feature combinations and fast evaluation speed. However, very few prior works focus on applying GBRT to feature extraction. One key observation is that certain 
%Some 
unique properties of GBRT, such as non-continuous boosted functions and optimization in function space, make GBRT well-suited for feature extraction. In this paper, we develop a novel algorithm called \fullname{} (\name{}), that leverages the unique properties of GBRT for feature extraction in two settings: budgeted learning and feature selection. 
%We give insights of unique properties of GBRT boosted functions, and derive our algorithm for test-time budgeted learning and non-linear feature selection. 
As part of the derivation, we give insights of unique properties of GBRT boosted functions that may be of independent interest. We further develop a simple method to estimate the lower bound of the prediction variance given extracted features using \name{}. We evaluate our algorithm on several real-world data sets for budgeted learning and feature selection, and demonstrate that \name{} outperforms the current state-of-the-art.